{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from modules.BatchPitNormalization import BatchPitNorm1d\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = np.genfromtxt('data/housing.csv', delimiter=\",\",skip_header=1)\n",
    "\n",
    "data = np.delete(data, [-1], axis=1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = data[:,:8]\n",
    "Y = data[:,8].reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "Y=Y[~np.isnan(X).any(axis=1)]\n",
    "X=X[~np.isnan(X).any(axis=1)]\n",
    "\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, Y, train_size = 0.7, shuffle = True)\n",
    "\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1,1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, device=device).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalHouse(\n",
      "  (hidden1): Linear(in_features=8, out_features=24, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=24, out_features=12, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=12, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CalHouse(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(8, 24)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(24, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        #self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        #x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "model = CalHouse()\n",
    "model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=24, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=24, out_features=12, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 35845828608.0\n",
      "test mse 56405110784.0\n",
      "Finished epoch 1, latest loss 21786013696.0\n",
      "test mse 37197361152.0\n",
      "Finished epoch 2, latest loss 9835098112.0\n",
      "test mse 15596406784.0\n",
      "Finished epoch 3, latest loss 6697920000.0\n",
      "test mse 11531998208.0\n",
      "Finished epoch 4, latest loss 5159887360.0\n",
      "test mse 10190953472.0\n",
      "Finished epoch 5, latest loss 3999731200.0\n",
      "test mse 9216128000.0\n",
      "Finished epoch 6, latest loss 3034359296.0\n",
      "test mse 8425476096.0\n",
      "Finished epoch 7, latest loss 2193419776.0\n",
      "test mse 7749109248.0\n",
      "Finished epoch 8, latest loss 1494653696.0\n",
      "test mse 7159703552.0\n",
      "Finished epoch 9, latest loss 1059746304.0\n",
      "test mse 6646645248.0\n",
      "Finished epoch 10, latest loss 805468288.0\n",
      "test mse 6225608704.0\n",
      "Finished epoch 11, latest loss 639354112.0\n",
      "test mse 5894470656.0\n",
      "Finished epoch 12, latest loss 494737408.0\n",
      "test mse 5647983104.0\n",
      "Finished epoch 13, latest loss 389759840.0\n",
      "test mse 5464070656.0\n",
      "Finished epoch 14, latest loss 329271232.0\n",
      "test mse 5324626432.0\n",
      "Finished epoch 15, latest loss 301790944.0\n",
      "test mse 5214931968.0\n",
      "Finished epoch 16, latest loss 297001184.0\n",
      "test mse 5126614016.0\n",
      "Finished epoch 17, latest loss 301888576.0\n",
      "test mse 5054606336.0\n",
      "Finished epoch 18, latest loss 310499040.0\n",
      "test mse 4996503040.0\n",
      "Finished epoch 19, latest loss 326048416.0\n",
      "test mse 4948577280.0\n",
      "Finished epoch 20, latest loss 343738368.0\n",
      "test mse 4909395968.0\n",
      "Finished epoch 21, latest loss 357923328.0\n",
      "test mse 4877049344.0\n",
      "Finished epoch 22, latest loss 370247392.0\n",
      "test mse 4850577920.0\n",
      "Finished epoch 23, latest loss 381033952.0\n",
      "test mse 4828308992.0\n",
      "Finished epoch 24, latest loss 390966496.0\n",
      "test mse 4809072128.0\n",
      "Finished epoch 25, latest loss 399233536.0\n",
      "test mse 4792624640.0\n",
      "Finished epoch 26, latest loss 405922752.0\n",
      "test mse 4778573312.0\n",
      "Finished epoch 27, latest loss 412269440.0\n",
      "test mse 4766366720.0\n",
      "Finished epoch 28, latest loss 416964480.0\n",
      "test mse 4755201024.0\n",
      "Finished epoch 29, latest loss 418509376.0\n",
      "test mse 4744956928.0\n",
      "Finished epoch 30, latest loss 415966688.0\n",
      "test mse 4735355392.0\n",
      "Finished epoch 31, latest loss 412886336.0\n",
      "test mse 4726252544.0\n",
      "Finished epoch 32, latest loss 409224800.0\n",
      "test mse 4717588480.0\n",
      "Finished epoch 33, latest loss 405243136.0\n",
      "test mse 4709288448.0\n",
      "Finished epoch 34, latest loss 401019520.0\n",
      "test mse 4701371904.0\n",
      "Finished epoch 35, latest loss 395924448.0\n",
      "test mse 4693877248.0\n",
      "Finished epoch 36, latest loss 390702304.0\n",
      "test mse 4686730752.0\n",
      "Finished epoch 37, latest loss 385052128.0\n",
      "test mse 4679954944.0\n",
      "Finished epoch 38, latest loss 379662944.0\n",
      "test mse 4673595392.0\n",
      "Finished epoch 39, latest loss 374060256.0\n",
      "test mse 4667524096.0\n",
      "Finished epoch 40, latest loss 368510816.0\n",
      "test mse 4661750784.0\n",
      "Finished epoch 41, latest loss 363333312.0\n",
      "test mse 4656304640.0\n",
      "Finished epoch 42, latest loss 357771456.0\n",
      "test mse 4651131904.0\n",
      "Finished epoch 43, latest loss 352266112.0\n",
      "test mse 4646189568.0\n",
      "Finished epoch 44, latest loss 346976896.0\n",
      "test mse 4641460736.0\n",
      "Finished epoch 45, latest loss 342080832.0\n",
      "test mse 4636900864.0\n",
      "Finished epoch 46, latest loss 337324896.0\n",
      "test mse 4632466432.0\n",
      "Finished epoch 47, latest loss 332616256.0\n",
      "test mse 4628203008.0\n",
      "Finished epoch 48, latest loss 326904224.0\n",
      "test mse 4624140288.0\n",
      "Finished epoch 49, latest loss 319696960.0\n",
      "test mse 4620286464.0\n",
      "Finished epoch 50, latest loss 311176640.0\n",
      "test mse 4616636416.0\n",
      "Finished epoch 51, latest loss 302811040.0\n",
      "test mse 4613213696.0\n",
      "Finished epoch 52, latest loss 294819616.0\n",
      "test mse 4609884672.0\n",
      "Finished epoch 53, latest loss 287292128.0\n",
      "test mse 4606670848.0\n",
      "Finished epoch 54, latest loss 279923424.0\n",
      "test mse 4603546112.0\n",
      "Finished epoch 55, latest loss 272791808.0\n",
      "test mse 4600533504.0\n",
      "Finished epoch 56, latest loss 266105792.0\n",
      "test mse 4597630976.0\n",
      "Finished epoch 57, latest loss 259817712.0\n",
      "test mse 4594867712.0\n",
      "Finished epoch 58, latest loss 253999008.0\n",
      "test mse 4592206336.0\n",
      "Finished epoch 59, latest loss 248514656.0\n",
      "test mse 4589606912.0\n",
      "Finished epoch 60, latest loss 243038192.0\n",
      "test mse 4587055616.0\n",
      "Finished epoch 61, latest loss 238166272.0\n",
      "test mse 4584593408.0\n",
      "Finished epoch 62, latest loss 233472768.0\n",
      "test mse 4582199296.0\n",
      "Finished epoch 63, latest loss 228982176.0\n",
      "test mse 4579847680.0\n",
      "Finished epoch 64, latest loss 224536192.0\n",
      "test mse 4577493504.0\n",
      "Finished epoch 65, latest loss 220195760.0\n",
      "test mse 4575268352.0\n",
      "Finished epoch 66, latest loss 216033328.0\n",
      "test mse 4573036544.0\n",
      "Finished epoch 67, latest loss 211797088.0\n",
      "test mse 4570831872.0\n",
      "Finished epoch 68, latest loss 207588064.0\n",
      "test mse 4568750080.0\n",
      "Finished epoch 69, latest loss 203304480.0\n",
      "test mse 4566588928.0\n",
      "Finished epoch 70, latest loss 199169536.0\n",
      "test mse 4564471296.0\n",
      "Finished epoch 71, latest loss 195412336.0\n",
      "test mse 4562417664.0\n",
      "Finished epoch 72, latest loss 191763456.0\n",
      "test mse 4560372736.0\n",
      "Finished epoch 73, latest loss 188445952.0\n",
      "test mse 4558279680.0\n",
      "Finished epoch 74, latest loss 185052544.0\n",
      "test mse 4556318208.0\n",
      "Finished epoch 75, latest loss 181640288.0\n",
      "test mse 4554342400.0\n",
      "Finished epoch 76, latest loss 178437296.0\n",
      "test mse 4552406528.0\n",
      "Finished epoch 77, latest loss 175290176.0\n",
      "test mse 4550447616.0\n",
      "Finished epoch 78, latest loss 172092736.0\n",
      "test mse 4548456960.0\n",
      "Finished epoch 79, latest loss 169272560.0\n",
      "test mse 4546489856.0\n",
      "Finished epoch 80, latest loss 166467120.0\n",
      "test mse 4544497664.0\n",
      "Finished epoch 81, latest loss 163702768.0\n",
      "test mse 4542566912.0\n",
      "Finished epoch 82, latest loss 161282640.0\n",
      "test mse 4540672000.0\n",
      "Finished epoch 83, latest loss 158630560.0\n",
      "test mse 4538762240.0\n",
      "Finished epoch 84, latest loss 156451872.0\n",
      "test mse 4536896512.0\n",
      "Finished epoch 85, latest loss 153952560.0\n",
      "test mse 4535040512.0\n",
      "Finished epoch 86, latest loss 151907360.0\n",
      "test mse 4533258240.0\n",
      "Finished epoch 87, latest loss 149811328.0\n",
      "test mse 4531457024.0\n",
      "Finished epoch 88, latest loss 147919488.0\n",
      "test mse 4529667584.0\n",
      "Finished epoch 89, latest loss 145294032.0\n",
      "test mse 4527878144.0\n",
      "Finished epoch 90, latest loss 142220736.0\n",
      "test mse 4526115328.0\n",
      "Finished epoch 91, latest loss 139028544.0\n",
      "test mse 4524333056.0\n",
      "Finished epoch 92, latest loss 135846336.0\n",
      "test mse 4522562048.0\n",
      "Finished epoch 93, latest loss 133036496.0\n",
      "test mse 4520826880.0\n",
      "Finished epoch 94, latest loss 130105904.0\n",
      "test mse 4519155200.0\n",
      "Finished epoch 95, latest loss 127375552.0\n",
      "test mse 4517449216.0\n",
      "Finished epoch 96, latest loss 124829552.0\n",
      "test mse 4515773952.0\n",
      "Finished epoch 97, latest loss 122408896.0\n",
      "test mse 4514142720.0\n",
      "Finished epoch 98, latest loss 120133168.0\n",
      "test mse 4512506880.0\n",
      "Finished epoch 99, latest loss 117928888.0\n",
      "test mse 4510858752.0\n"
     ]
    }
   ],
   "source": [
    "lossFunction = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 20\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        Xbatch = X_train[i:i+batch_size]\n",
    "        ybatch = y_train[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        loss = lossFunction(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
